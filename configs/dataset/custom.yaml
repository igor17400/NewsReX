_target_: src.datasets.custom_dataset.CustomDataset

# Inherit from base configuration
defaults:
- base

# Dataset configuration
name: "CustomDataset"  # Customizable dataset name
version: "v1"  # Dataset version identifier
language: "english"  # Language of the dataset (english, spanish, portuguese, etc.)
data_path: null  # Optional: Path to dataset directory (if null, uses cache directory)
download_if_missing: true  # Whether to download dataset if not found

# Embedding configuration based on language
embedding_type: "bpemb"  # Options: bpemb (multilingual), glove (english only), random
embedding_size: 300  # Size of the embeddings (BPEmb supports: 25, 50, 100, 200, 300)

# Dataset behavior configuration
random_train_samples: false
validation_split_strategy: "random"  # Options: chronological, random
validation_split_percentage: 0.05
validation_split_seed: 42

# Data sampling fractions
data_fraction_train: 1.0
data_fraction_val: 1.0
data_fraction_test: 1.0

# Dataset mode
mode: "train"

# Word threshold for vocabulary
word_threshold: 5

# Dataset URLs (can be null if data is local)
# Replace these with your actual dataset URLs following MIND format
urls: null
# Example structure for URLs:
# urls:
#   train: "https://your-domain.com/dataset_train.zip"
#   valid: "https://your-domain.com/dataset_valid.zip"
#   test: "https://your-domain.com/dataset_test.zip"  # Optional

# Preprocessing parameters
max_title_length: 30
max_abstract_length: 50
max_history_length: 50
max_impressions_length: 5

# Knowledge graph configuration
use_knowledge_graph: false  # Enable/disable knowledge graph processing
max_entities: 100
max_relations: 50

# Pass sampling configuration directly
sampling: ${sampling}

# Process Title / Abstract / Category / Subcategory / User ID
process_title: false
process_abstract: false
process_category: false
process_subcategory: false
process_user_id: false